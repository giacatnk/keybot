{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# KeyBot: Accurate and Efficient Vertebrae Keypoint Estimation\n",
        "## ECCV 2024 - Demo Notebook\n",
        "\n",
        "**Paper:** *Bones Can't Be Triangles: Accurate and Efficient Vertebrae Keypoint Estimation through Collaborative Error Revision*\n",
        "\n",
        "---\n",
        "\n",
        "This notebook demonstrates the KeyBot system for vertebrae keypoint estimation on spine X-ray images.\n",
        "\n",
        "### System Overview:\n",
        "- **Refiner**: Interactive keypoint estimation model (RITM_SE_HRNet32)\n",
        "- **Detector**: Identifies potential errors in predictions\n",
        "- **Corrector**: Automatically revises detected errors\n",
        "\n",
        "### Dataset:\n",
        "- AASCE (Anterior-Posterior Spinal X-rays)\n",
        "- 68 keypoints per image (4 corners per vertebra Ã— 17 vertebrae)\n",
        "- Image size: 512Ã—256 pixels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard imports\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "from PIL import Image\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configure matplotlib for better visualizations\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "    \n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"\\nâœ“ Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup paths and imports from codes directory\n",
        "original_dir = os.getcwd()\n",
        "codes_dir = os.path.join(original_dir, 'codes')\n",
        "\n",
        "# Add codes directory to path and change to it (required for imports)\n",
        "sys.path.insert(0, codes_dir)\n",
        "os.chdir(codes_dir)\n",
        "\n",
        "# Import KeyBot modules\n",
        "from AnomalySuggestion_get_model import get_keypoint_model, get_test_data_loader, test\n",
        "from suggest_codes.get_suggest_model import SuggestionConvModel\n",
        "from suggest_codes.get_suggest_dataset import SuggestionDataset\n",
        "from suggest_codes.get_pseudo_generation_model_image_heatmap import PseudoLabelModel, get_func_pseudo_label\n",
        "from suggest_codes.get_pseudo_generation_dataset_image_negative_sample import RefineDataset\n",
        "from util import DEVICE\n",
        "\n",
        "print(\"âœ“ All modules imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Pre-trained Models\n",
        "\n",
        "We load three models that work collaboratively:\n",
        "1. **Refiner**: Base keypoint estimation model\n",
        "2. **Detector**: Identifies error-prone keypoints\n",
        "3. **Corrector**: Refines detected errors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Loading models...\\n\")\n",
        "\n",
        "# 1. Load Refiner (Base Interactive Keypoint Model)\n",
        "print(\"[1/3] Loading Refiner (RITM_SE_HRNet32)...\")\n",
        "trainer, save_manager = get_keypoint_model(data='spineweb')\n",
        "refiner = trainer.model\n",
        "refiner.eval()\n",
        "print(\"  âœ“ Refiner loaded\")\n",
        "\n",
        "# 2. Load Detector (Suggestion Model)\n",
        "print(\"\\n[2/3] Loading Detector (Error Detection)...\")\n",
        "detector = SuggestionConvModel()\n",
        "detector_path = os.path.join(original_dir, 'save_suggestion', 'AASCE_suggestModel.pth')\n",
        "if os.path.exists(detector_path):\n",
        "    detector.load_state_dict(torch.load(detector_path, map_location=DEVICE))\n",
        "    detector.eval()\n",
        "    detector.to(DEVICE)\n",
        "    print(\"  âœ“ Detector loaded\")\n",
        "else:\n",
        "    print(f\"  âš  Warning: Detector not found at {detector_path}\")\n",
        "\n",
        "# 3. Load Corrector (Pseudo Label Model)\n",
        "print(\"\\n[3/3] Loading Corrector (Error Refinement)...\")\n",
        "corrector = PseudoLabelModel(n_keypoint=68, num_bones=17)\n",
        "corrector_path = os.path.join(original_dir, 'save_refine', 'AASCE_refineModel.pth')\n",
        "if os.path.exists(corrector_path):\n",
        "    corrector.load_state_dict(torch.load(corrector_path, map_location=DEVICE))\n",
        "    corrector.eval()\n",
        "    corrector.to(DEVICE)\n",
        "    print(\"  âœ“ Corrector loaded\")\n",
        "else:\n",
        "    print(f\"  âš  Warning: Corrector not found at {corrector_path}\")\n",
        "\n",
        "get_pseudo_label = get_func_pseudo_label()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"âœ“ All models loaded successfully!\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load Test Data\n",
        "\n",
        "Load the AASCE test dataset with preprocessed spine X-ray images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Loading test data...\")\n",
        "keypoint_train_loader, keypoint_val_loader, keypoint_test_loader = get_test_data_loader(\n",
        "    off_train_aug=True, \n",
        "    data='spineweb'\n",
        ")\n",
        "\n",
        "print(f\"âœ“ Test dataset loaded\")\n",
        "print(f\"  - Test samples: {len(keypoint_test_loader.dataset)}\")\n",
        "print(f\"  - Batch size: {keypoint_test_loader.batch_size}\")\n",
        "print(f\"  - Image size: 512Ã—256 pixels\")\n",
        "print(f\"  - Keypoints per image: 68 (17 vertebrae Ã— 4 corners)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Single Image Demo: Inference Pipeline\n",
        "\n",
        "Let's run inference on a single test image to demonstrate the KeyBot pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get a single test image\n",
        "batch = next(iter(keypoint_test_loader))\n",
        "\n",
        "image = batch['input_image'][0]  # Shape: (3, 512, 256)\n",
        "gt_coords = batch['label']['coord'][0]  # Shape: (68, 2)\n",
        "gt_heatmap = batch['label']['heatmap'][0]  # Shape: (68, 512, 256)\n",
        "image_path = batch['input_image_path'][0]\n",
        "\n",
        "print(f\"Selected image: {image_path}\")\n",
        "print(f\"\\nData shapes:\")\n",
        "print(f\"  - Input image: {tuple(image.shape)}\")\n",
        "print(f\"  - GT coordinates: {tuple(gt_coords.shape)}\")\n",
        "print(f\"  - GT heatmap: {tuple(gt_heatmap.shape)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the input image\n",
        "def denormalize_image(img_tensor):\n",
        "    \"\"\"Convert normalized tensor to displayable image\"\"\"\n",
        "    img = img_tensor.permute(1, 2, 0).cpu().numpy()\n",
        "    img = (img + 1) / 2  # [-1, 1] -> [0, 1]\n",
        "    img = np.clip(img, 0, 1)\n",
        "    return img.mean(axis=2)  # Convert to grayscale\n",
        "\n",
        "display_image = denormalize_image(image)\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(6, 10))\n",
        "ax.imshow(display_image, cmap='gray')\n",
        "ax.set_title('Input X-ray Image', fontsize=14, fontweight='bold')\n",
        "ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Image dimensions: {display_image.shape[0]}Ã—{display_image.shape[1]} pixels\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run inference with the Refiner (base model)\n",
        "print(\"Running inference with Refiner...\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Prepare batch\n",
        "    batch['is_training'] = False\n",
        "    batch['hint'] = {'index': [None]}  # No manual hints\n",
        "    \n",
        "    # Forward pass\n",
        "    out, batch = refiner(batch)\n",
        "    \n",
        "    # Extract predictions\n",
        "    pred_coords = out.pred.sargmax_coord[0].cpu()  # (68, 2)\n",
        "    pred_heatmap = out.pred.heatmap[0].cpu()  # (68, 512, 256)\n",
        "\n",
        "# Compute error metrics\n",
        "def compute_mre(pred, gt):\n",
        "    \"\"\"Mean Radial Error in pixels\"\"\"\n",
        "    return torch.sqrt(((pred - gt.cpu())**2).sum(-1)).mean().item()\n",
        "\n",
        "def compute_sdr(pred, gt, threshold=2.0):\n",
        "    \"\"\"Success Detection Rate (% within threshold)\"\"\"\n",
        "    errors = torch.sqrt(((pred - gt.cpu())**2).sum(-1))\n",
        "    return (errors <= threshold).float().mean().item() * 100\n",
        "\n",
        "mre = compute_mre(pred_coords, gt_coords)\n",
        "sdr_2mm = compute_sdr(pred_coords, gt_coords, threshold=2.0)\n",
        "sdr_4mm = compute_sdr(pred_coords, gt_coords, threshold=4.0)\n",
        "\n",
        "print(f\"\\nâœ“ Inference complete\")\n",
        "print(f\"\\nðŸ“Š Metrics:\")\n",
        "print(f\"  - Mean Radial Error (MRE): {mre:.2f} pixels\")\n",
        "print(f\"  - SDR@2mm: {sdr_2mm:.1f}%\")\n",
        "print(f\"  - SDR@4mm: {sdr_4mm:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Visualization: Predictions vs Ground Truth\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive visualization\n",
        "gt_coords_np = gt_coords.cpu().numpy()\n",
        "pred_coords_np = pred_coords.numpy()\n",
        "errors = torch.sqrt(((pred_coords - gt_coords.cpu())**2).sum(-1))\n",
        "errors_np = errors.numpy()\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "# 1. Ground Truth\n",
        "ax = axes[0, 0]\n",
        "ax.imshow(display_image, cmap='gray')\n",
        "scatter = ax.scatter(gt_coords_np[:, 1], gt_coords_np[:, 0], \n",
        "                     c='lime', s=40, alpha=0.8, edgecolors='darkgreen', linewidths=1)\n",
        "ax.set_title('Ground Truth Keypoints', fontsize=13, fontweight='bold')\n",
        "ax.axis('off')\n",
        "\n",
        "# 2. Predictions\n",
        "ax = axes[0, 1]\n",
        "ax.imshow(display_image, cmap='gray')\n",
        "ax.scatter(pred_coords_np[:, 1], pred_coords_np[:, 0], \n",
        "           c='red', s=40, alpha=0.8, edgecolors='darkred', linewidths=1, marker='x')\n",
        "ax.set_title('Model Predictions', fontsize=13, fontweight='bold')\n",
        "ax.axis('off')\n",
        "\n",
        "# 3. Overlay with Error Lines\n",
        "ax = axes[0, 2]\n",
        "ax.imshow(display_image, cmap='gray')\n",
        "ax.scatter(gt_coords_np[:, 1], gt_coords_np[:, 0], \n",
        "           c='lime', s=50, alpha=0.7, label='Ground Truth', marker='o')\n",
        "ax.scatter(pred_coords_np[:, 1], pred_coords_np[:, 0], \n",
        "           c='red', s=40, alpha=0.7, label='Prediction', marker='x')\n",
        "# Draw error lines\n",
        "for i in range(len(gt_coords_np)):\n",
        "    ax.plot([gt_coords_np[i, 1], pred_coords_np[i, 1]], \n",
        "            [gt_coords_np[i, 0], pred_coords_np[i, 0]], \n",
        "            'yellow', linewidth=0.8, alpha=0.5)\n",
        "ax.set_title(f'Comparison (MRE: {mre:.2f}px)', fontsize=13, fontweight='bold')\n",
        "ax.legend(loc='upper right')\n",
        "ax.axis('off')\n",
        "\n",
        "# 4. Ground Truth Heatmap\n",
        "ax = axes[1, 0]\n",
        "gt_heatmap_sum = gt_heatmap.cpu().sum(dim=0)\n",
        "ax.imshow(display_image, cmap='gray', alpha=0.6)\n",
        "im = ax.imshow(gt_heatmap_sum, cmap='hot', alpha=0.5)\n",
        "ax.set_title('Ground Truth Heatmap', fontsize=13, fontweight='bold')\n",
        "ax.axis('off')\n",
        "plt.colorbar(im, ax=ax, fraction=0.046)\n",
        "\n",
        "# 5. Predicted Heatmap\n",
        "ax = axes[1, 1]\n",
        "pred_heatmap_sum = pred_heatmap.sum(dim=0)\n",
        "ax.imshow(display_image, cmap='gray', alpha=0.6)\n",
        "im = ax.imshow(pred_heatmap_sum, cmap='hot', alpha=0.5)\n",
        "ax.set_title('Predicted Heatmap', fontsize=13, fontweight='bold')\n",
        "ax.axis('off')\n",
        "plt.colorbar(im, ax=ax, fraction=0.046)\n",
        "\n",
        "# 6. Per-Keypoint Error Visualization\n",
        "ax = axes[1, 2]\n",
        "ax.imshow(display_image, cmap='gray', alpha=0.7)\n",
        "scatter = ax.scatter(pred_coords_np[:, 1], pred_coords_np[:, 0], \n",
        "                     c=errors_np, s=100, alpha=0.8, cmap='RdYlGn_r', \n",
        "                     edgecolors='black', linewidths=1, vmin=0, vmax=errors_np.max())\n",
        "ax.set_title(f'Per-Keypoint Error (Max: {errors_np.max():.2f}px)', fontsize=13, fontweight='bold')\n",
        "ax.axis('off')\n",
        "cbar = plt.colorbar(scatter, ax=ax, fraction=0.046)\n",
        "cbar.set_label('Error (pixels)', rotation=270, labelpad=15)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nVisualization shows:\")\n",
        "print(\"  Top row: Keypoint locations (GT, Pred, Overlay)\")\n",
        "print(\"  Bottom row: Heatmaps and per-keypoint errors\")\n",
        "print(\"  Red/Hot colors in error map indicate higher localization errors\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Interactive Exploration: Browse Test Samples\n",
        "\n",
        "Browse through different test samples to see predictions on various spine X-rays.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_sample(sample_idx, test_loader):\n",
        "    \"\"\"\n",
        "    Visualize a specific test sample with predictions\n",
        "    \n",
        "    Args:\n",
        "        sample_idx: Index of the sample to visualize\n",
        "        test_loader: DataLoader for test data\n",
        "    \"\"\"\n",
        "    # Get the sample\n",
        "    dataset = test_loader.dataset\n",
        "    if sample_idx >= len(dataset):\n",
        "        print(f\"Error: sample_idx {sample_idx} out of range (max: {len(dataset)-1})\")\n",
        "        return\n",
        "    \n",
        "    sample = dataset[sample_idx]\n",
        "    \n",
        "    # Prepare batch\n",
        "    batch = {\n",
        "        'input_image': sample['input_image'].unsqueeze(0),\n",
        "        'label': {\n",
        "            'coord': sample['label']['coord'].unsqueeze(0),\n",
        "            'heatmap': sample['label']['heatmap'].unsqueeze(0),\n",
        "        },\n",
        "        'input_image_path': [sample['input_image_path']],\n",
        "        'is_training': False,\n",
        "        'hint': {'index': [None]}\n",
        "    }\n",
        "    \n",
        "    # Run inference\n",
        "    with torch.no_grad():\n",
        "        out, batch = refiner(batch)\n",
        "        pred_coords = out.pred.sargmax_coord[0].cpu()\n",
        "    \n",
        "    # Extract data\n",
        "    image = sample['input_image']\n",
        "    gt_coords = sample['label']['coord'].cpu()\n",
        "    \n",
        "    # Compute metrics\n",
        "    mre = compute_mre(pred_coords, gt_coords)\n",
        "    sdr_2mm = compute_sdr(pred_coords, gt_coords, 2.0)\n",
        "    sdr_4mm = compute_sdr(pred_coords, gt_coords, 4.0)\n",
        "    \n",
        "    # Visualize\n",
        "    display_img = denormalize_image(image)\n",
        "    gt_np = gt_coords.numpy()\n",
        "    pred_np = pred_coords.numpy()\n",
        "    errors = torch.sqrt(((pred_coords - gt_coords)**2).sum(-1)).numpy()\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "    \n",
        "    # Ground Truth\n",
        "    axes[0].imshow(display_img, cmap='gray')\n",
        "    axes[0].scatter(gt_np[:, 1], gt_np[:, 0], c='lime', s=40, alpha=0.8)\n",
        "    axes[0].set_title('Ground Truth', fontsize=13, fontweight='bold')\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    # Predictions\n",
        "    axes[1].imshow(display_img, cmap='gray')\n",
        "    axes[1].scatter(pred_np[:, 1], pred_np[:, 0], c='red', s=40, alpha=0.8, marker='x')\n",
        "    axes[1].set_title('Predictions', fontsize=13, fontweight='bold')\n",
        "    axes[1].axis('off')\n",
        "    \n",
        "    # Error Map\n",
        "    axes[2].imshow(display_img, cmap='gray', alpha=0.7)\n",
        "    scatter = axes[2].scatter(pred_np[:, 1], pred_np[:, 0], c=errors, s=100, \n",
        "                              cmap='RdYlGn_r', alpha=0.8, edgecolors='black', linewidths=1)\n",
        "    axes[2].set_title(f'Error Map', fontsize=13, fontweight='bold')\n",
        "    axes[2].axis('off')\n",
        "    plt.colorbar(scatter, ax=axes[2], fraction=0.046, label='Error (pixels)')\n",
        "    \n",
        "    plt.suptitle(f\"Sample {sample_idx} | MRE: {mre:.2f}px | SDR@2mm: {sdr_2mm:.1f}% | SDR@4mm: {sdr_4mm:.1f}%\",\n",
        "                 fontsize=14, fontweight='bold', y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"Image: {sample['input_image_path']}\")\n",
        "    print(f\"MRE: {mre:.2f} pixels | SDR@2mm: {sdr_2mm:.1f}% | SDR@4mm: {sdr_4mm:.1f}%\")\n",
        "\n",
        "# Show the first sample\n",
        "print(f\"Total test samples: {len(keypoint_test_loader.dataset)}\\n\")\n",
        "visualize_sample(0, keypoint_test_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive widget to browse samples\n",
        "# Change the sample_idx value to view different samples (0 to N-1)\n",
        "\n",
        "sample_idx = 5  # Change this value!\n",
        "\n",
        "visualize_sample(sample_idx, keypoint_test_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get a sample for vertebrae analysis\n",
        "batch = next(iter(keypoint_test_loader))\n",
        "\n",
        "with torch.no_grad():\n",
        "    batch['is_training'] = False\n",
        "    batch['hint'] = {'index': [None]}\n",
        "    out, batch = refiner(batch)\n",
        "    pred_coords = out.pred.sargmax_coord[0].cpu()\n",
        "\n",
        "image = batch['input_image'][0]\n",
        "gt_coords = batch['label']['coord'][0].cpu()\n",
        "display_img = denormalize_image(image)\n",
        "\n",
        "# Visualize vertebrae structure\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 10))\n",
        "\n",
        "# Define colors for each vertebra\n",
        "colors = plt.cm.rainbow(np.linspace(0, 1, 17))\n",
        "\n",
        "# Ground Truth Vertebrae\n",
        "ax = axes[0]\n",
        "ax.imshow(display_img, cmap='gray')\n",
        "for vertebra_idx in range(17):\n",
        "    # Each vertebra has 4 keypoints (corners)\n",
        "    start_idx = vertebra_idx * 4\n",
        "    end_idx = start_idx + 4\n",
        "    vertebra_coords = gt_coords[start_idx:end_idx].numpy()\n",
        "    \n",
        "    # Plot corners\n",
        "    ax.scatter(vertebra_coords[:, 1], vertebra_coords[:, 0], \n",
        "               c=[colors[vertebra_idx]], s=50, alpha=0.8, edgecolors='black', linewidths=1)\n",
        "    \n",
        "    # Draw bounding box for vertebra\n",
        "    min_y, max_y = vertebra_coords[:, 0].min(), vertebra_coords[:, 0].max()\n",
        "    min_x, max_x = vertebra_coords[:, 1].min(), vertebra_coords[:, 1].max()\n",
        "    \n",
        "    rect = Rectangle((min_x, min_y), max_x - min_x, max_y - min_y,\n",
        "                      fill=False, edgecolor=colors[vertebra_idx], linewidth=2, alpha=0.7)\n",
        "    ax.add_patch(rect)\n",
        "    \n",
        "    # Label vertebra\n",
        "    center_y = (min_y + max_y) / 2\n",
        "    center_x = (min_x + max_x) / 2\n",
        "    ax.text(center_x, center_y, f'V{vertebra_idx+1}', \n",
        "            fontsize=8, color='white', ha='center', va='center',\n",
        "            bbox=dict(boxstyle='round,pad=0.3', facecolor=colors[vertebra_idx], alpha=0.7))\n",
        "\n",
        "ax.set_title('Ground Truth Vertebrae (17 vertebrae, 4 keypoints each)', \n",
        "             fontsize=12, fontweight='bold')\n",
        "ax.axis('off')\n",
        "\n",
        "# Predicted Vertebrae\n",
        "ax = axes[1]\n",
        "ax.imshow(display_img, cmap='gray')\n",
        "for vertebra_idx in range(17):\n",
        "    start_idx = vertebra_idx * 4\n",
        "    end_idx = start_idx + 4\n",
        "    vertebra_coords = pred_coords[start_idx:end_idx].numpy()\n",
        "    \n",
        "    ax.scatter(vertebra_coords[:, 1], vertebra_coords[:, 0], \n",
        "               c=[colors[vertebra_idx]], s=50, alpha=0.8, edgecolors='black', linewidths=1)\n",
        "    \n",
        "    min_y, max_y = vertebra_coords[:, 0].min(), vertebra_coords[:, 0].max()\n",
        "    min_x, max_x = vertebra_coords[:, 1].min(), vertebra_coords[:, 1].max()\n",
        "    \n",
        "    rect = Rectangle((min_x, min_y), max_x - min_x, max_y - min_y,\n",
        "                      fill=False, edgecolor=colors[vertebra_idx], linewidth=2, alpha=0.7)\n",
        "    ax.add_patch(rect)\n",
        "    \n",
        "    center_y = (min_y + max_y) / 2\n",
        "    center_x = (min_x + max_x) / 2\n",
        "    ax.text(center_x, center_y, f'V{vertebra_idx+1}', \n",
        "            fontsize=8, color='white', ha='center', va='center',\n",
        "            bbox=dict(boxstyle='round,pad=0.3', facecolor=colors[vertebra_idx], alpha=0.7))\n",
        "\n",
        "ax.set_title('Predicted Vertebrae', fontsize=12, fontweight='bold')\n",
        "ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Each vertebra is labeled V1-V17 (from bottom to top of spine)\")\n",
        "print(\"Each vertebra has 4 corner keypoints forming a rectangular region\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Change back to original directory\n",
        "os.chdir(original_dir)\n",
        "\n",
        "# Create output directory\n",
        "output_dir = os.path.join(original_dir, 'demo_outputs')\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Output directory created: {output_dir}\")\n",
        "print(\"\\nYou can save visualizations using plt.savefig() in the cells above.\")\n",
        "print(\"\\nExample:\")\n",
        "print(\"  plt.savefig(os.path.join(output_dir, 'visualization.png'), dpi=150, bbox_inches='tight')\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"âœ“ Demo notebook complete!\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nThank you for exploring KeyBot!\")\n",
        "print(\"For more information, visit: https://ts-kim.github.io/KeyBot/\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
